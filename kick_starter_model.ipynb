{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import  f1_score, roc_auc_score, roc_curve, precision_score, recall_score, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               blurb            country  \\\n0  Support great art! Join us as we re-stage the ...  the United States   \n1  JinBucha is a new kind of Brewery in North Par...  the United States   \n2  \"Taste The Scent of Tea\" Rose and Blanc Tea Ro...  the United States   \n3  Bringing Philly cheesesteaks (and other delici...  the United States   \n4  a frog plushie keychain and frog butt pin for ...  the United States   \n\n      goal  launched_at  campaign_success category     subcategory  \\\n0   3000.0   1580433192                 1    Dance    Performances   \n1  20000.0   1447526057                 0     Food          Drinks   \n2  15000.0   1518208887                 0     Food          Drinks   \n3   2000.0   1454705444                 0     Food     Food Trucks   \n4    800.0   1573236000                 1   Design  Product Design   \n\n   campaign_length  \n0        30.000000  \n1        30.000000  \n2        23.430243  \n3        59.958333  \n4        14.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>blurb</th>\n      <th>country</th>\n      <th>goal</th>\n      <th>launched_at</th>\n      <th>campaign_success</th>\n      <th>category</th>\n      <th>subcategory</th>\n      <th>campaign_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Support great art! Join us as we re-stage the ...</td>\n      <td>the United States</td>\n      <td>3000.0</td>\n      <td>1580433192</td>\n      <td>1</td>\n      <td>Dance</td>\n      <td>Performances</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>JinBucha is a new kind of Brewery in North Par...</td>\n      <td>the United States</td>\n      <td>20000.0</td>\n      <td>1447526057</td>\n      <td>0</td>\n      <td>Food</td>\n      <td>Drinks</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Taste The Scent of Tea\" Rose and Blanc Tea Ro...</td>\n      <td>the United States</td>\n      <td>15000.0</td>\n      <td>1518208887</td>\n      <td>0</td>\n      <td>Food</td>\n      <td>Drinks</td>\n      <td>23.430243</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bringing Philly cheesesteaks (and other delici...</td>\n      <td>the United States</td>\n      <td>2000.0</td>\n      <td>1454705444</td>\n      <td>0</td>\n      <td>Food</td>\n      <td>Food Trucks</td>\n      <td>59.958333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a frog plushie keychain and frog butt pin for ...</td>\n      <td>the United States</td>\n      <td>800.0</td>\n      <td>1573236000</td>\n      <td>1</td>\n      <td>Design</td>\n      <td>Product Design</td>\n      <td>14.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df1 = pd.read_csv('/Users/charliemay/Desktop/kickstarter_project/DS/clean_kickstart_data.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign datatypes for\n",
    "df1['blurb'] = df1['blurb'].astype(str)\n",
    "df1['country'] = df1['country'].astype(str)\n",
    "df1['campaign_success'] = df1['campaign_success'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(86636, 7)\n(45201, 7)\n(47619, 7)\n"
    }
   ],
   "source": [
    "# Choose cutoffs based on unix time\n",
    "cutoff1 = 1466003000\n",
    "cutoff2 = 1530120000\n",
    "\n",
    "test = df1[df1['launched_at']>=cutoff2]\n",
    "train = df1[df1['launched_at']<cutoff2]\n",
    "val = train[train['launched_at']>cutoff1] \n",
    "train = train[train['launched_at']<=cutoff1]\n",
    "\n",
    "# Drop launched_at column, not used in model\n",
    "train = train.drop(columns=['launched_at'])\n",
    "val = val.drop(columns=['launched_at']) \n",
    "test = test.drop(columns=['launched_at'])\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target, is the client a defaulter\n",
    "target = 'campaign_success'\n",
    "\n",
    "# Features\n",
    "features = list(train.drop(columns = [target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "#Create and train transformations\n",
    "# Encode catagorical features on X_train\n",
    "encoder = ce.OrdinalEncoder(cols=['country', 'category', 'subcategory'])\n",
    "encoder.fit(X_train)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(X, encoder):\n",
    "\n",
    "    # copy to avoid errors\n",
    "    X = X.reset_index(drop=True).copy()\n",
    "\n",
    "    X = encoder.transform(X)\n",
    "\n",
    "    X['blurb_length'] = X['blurb'].apply(lambda x: len(x))\n",
    "    X['blurb_words'] = X['blurb'].apply(lambda x: len(x.split()))\n",
    "    X['blurb_uppers'] = X['blurb'].apply(lambda x: sum(map(str.isupper, x.split())))\n",
    "    X['blurb_qmarks'] = X['blurb'].apply(lambda x: x.count(\"?\"))\n",
    "    X['blub_exclamation'] = X['blurb'].apply(lambda x: x.count(\"!\"))\n",
    "    X = X.drop(columns=['blurb'])\n",
    "\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(86636, 10)\n(45201, 10)\n(47619, 10)\n"
    }
   ],
   "source": [
    "X_train_e = wrangle(X_train, encoder)\n",
    "X_val_e = wrangle(X_val, encoder)\n",
    "X_test_e = wrangle(X_test, encoder)\n",
    "print(X_train_e.shape)\n",
    "print(X_val_e.shape)\n",
    "print(X_test_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define Model\"\"\"\n",
    "# First XGBoost Model\n",
    "booster= XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# XBG Simple\n",
    "xgb_simple= booster.fit(X_train_e, y_train) #fit on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [Model, True -, False +, False -, True +, Accuracy, Precision, Recall]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>True -</th>\n      <th>False +</th>\n      <th>False -</th>\n      <th>True +</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Create dataframe to track outcomes\n",
    "columns =['Model','True -', 'False +', 'False -','True +','Accuracy', 'Precision', 'Recall']\n",
    "tracker= pd.DataFrame(columns=columns)\n",
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add rows to tracking dataframe\n",
    "# m_name = Model Name\n",
    "\n",
    "def row_maker(m_name, y, pred):\n",
    "  tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "  recall = round((tp/(tp+fn)),2) # true positive rate\n",
    "  n_recall = round((tn/(tn+fp)),2) #true negative rate\n",
    "  precision = round((tp/(tp+fp)),2) # true positive rate\n",
    "  top = tp+tn\n",
    "  bottom = tn+fp+fn+tp\n",
    "  accuracy = round(((tp+tn)/(tp+tn+fp+fn)),2) # accuracy\n",
    "  # accuracy = round((top/bottom),2) # accuracy\n",
    "  new_row = {'Model':m_name,'True -':tn, 'False +':fp, 'False -':fn,'True +':tp ,'Accuracy':accuracy,'Precision':precision, 'Recall':recall}\n",
    "  return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Classification Report:\n\n               precision    recall  f1-score   support\n\n           0       0.73      0.73      0.73     21196\n           1       0.76      0.76      0.76     24005\n\n    accuracy                           0.75     45201\n   macro avg       0.74      0.75      0.74     45201\nweighted avg       0.75      0.75      0.75     45201\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Model True - False + False - True +  Accuracy  Precision  Recall\n0  XGBoost Simple  15507    5689    5798  18207      0.75       0.76    0.76",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>True -</th>\n      <th>False +</th>\n      <th>False -</th>\n      <th>True +</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost Simple</td>\n      <td>15507</td>\n      <td>5689</td>\n      <td>5798</td>\n      <td>18207</td>\n      <td>0.75</td>\n      <td>0.76</td>\n      <td>0.76</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\"\"\" Run Model XGBoost Simple \"\"\"\n",
    "xs_y_pred_v = booster.predict(X_val_e)\n",
    "\n",
    "m_name = 'XGBoost Simple'\n",
    "y = y_val\n",
    "pred = xs_y_pred_v\n",
    "\n",
    "print('Classification Report:\\n\\n', classification_report(y, pred))\n",
    "\n",
    "# tracking dataframe\n",
    "new_row=row_maker(m_name, y, pred)\n",
    "tracker = tracker.append(new_row, ignore_index=True)\n",
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Classification Report:\n\n               precision    recall  f1-score   support\n\n           0       0.65      0.64      0.64     15914\n           1       0.82      0.83      0.82     31705\n\n    accuracy                           0.76     47619\n   macro avg       0.73      0.73      0.73     47619\nweighted avg       0.76      0.76      0.76     47619\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 Model True - False + False - True +  Accuracy  Precision  \\\n0       XGBoost Simple  15507    5689    5798  18207      0.75       0.76   \n1  XGBoost Simple TEST  10133    5781    5482  26223      0.76       0.82   \n\n   Recall  \n0    0.76  \n1    0.83  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>True -</th>\n      <th>False +</th>\n      <th>False -</th>\n      <th>True +</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost Simple</td>\n      <td>15507</td>\n      <td>5689</td>\n      <td>5798</td>\n      <td>18207</td>\n      <td>0.75</td>\n      <td>0.76</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XGBoost Simple TEST</td>\n      <td>10133</td>\n      <td>5781</td>\n      <td>5482</td>\n      <td>26223</td>\n      <td>0.76</td>\n      <td>0.82</td>\n      <td>0.83</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "\"\"\" Run Model\"\"\"\n",
    "xs_y_pred_test = booster.predict(X_test_e)\n",
    "\n",
    "m_name = 'XGBoost Simple TEST'\n",
    "model =  booster.fit(X_train_e, y_train)\n",
    "X = X_test_e\n",
    "y = y_test\n",
    "pred = xs_y_pred_test\n",
    "\n",
    "print('Classification Report:\\n\\n', classification_report(y, pred))\n",
    "\n",
    "# tracking dataframe\n",
    "new_row=row_maker(m_name, y, pred)\n",
    "tracker = tracker.append(new_row, ignore_index=True)\n",
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(encoder, 'encoder1.joblib' )\n",
    "encoder1 = load('encoder1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle Function to 'Pickle'\n",
    "\n",
    "def wrangler(X, encoder):\n",
    "  X = pd.DataFrame.from_dict(X, orient='index')\n",
    "  X = X.T\n",
    "  X = X.reset_index(drop=True).copy()\n",
    "  X.rename(columns={'x1':'goal',\n",
    "                    'x2':'campaign_length',\n",
    "                    'x3':'country',\n",
    "                    'x4':'category',\n",
    "                    'x5':'subcategory',\n",
    "                    'x6':'blurb'}, inplace=True)\n",
    "\n",
    "  X = encoder.transform(X)\n",
    "  X = X[['country', 'goal', 'category', 'subcategory',\n",
    "         'campaign_length', 'blurb']]\n",
    "\n",
    "  X['blurb_length'] = X['blurb'].apply(lambda x: len(x))\n",
    "  X['blurb_words'] = X['blurb'].apply(lambda x: len(x.split()))\n",
    "  X['blurb_uppers'] = X['blurb'].apply(lambda x: sum(map(str.isupper, x.split())))\n",
    "  X['blurb_qmarks'] = X['blurb'].apply(lambda x: x.count(\"?\"))\n",
    "  X['blub_exclamation'] = X['blurb'].apply(lambda x: x.count(\"!\"))\n",
    "  X = X.drop(columns=['blurb'])\n",
    "  X = X.astype(int)\n",
    "  return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(wrangler, 'wrangler1.joblib' )\n",
    "wrangler1 = load('wrangler1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model to Pickle\n",
    "def kick_boost(X):\n",
    "  prediction = booster.predict_proba(X)[0][1]\n",
    "  prediction = round(prediction, 3)\n",
    "  \n",
    "  return(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(kick_boost, 'kick_boost1.joblib' )\n",
    "kick_boost1 = load('kick_boost1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Data\n",
    "test_1 = {\n",
    "  \"x1\": 10000,\n",
    "  \"x2\": 8,\n",
    "  \"x3\": \"Canada\",\n",
    "  \"x4\": \"Science\",\n",
    "  \"x5\": \"Material Thread Science\",\n",
    "  \"x6\": \"I am making somthing that will do something awesome!!! Answer the question 'will it be amazing?'\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.37"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "result = wrangler1(test_1, encoder1)\n",
    "prediction = kick_boost1(result)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitdspipenv981fd23ff60e48cca7e4321e2db599c6",
   "display_name": "Python 3.8.3 64-bit ('DS': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}